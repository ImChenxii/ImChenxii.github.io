

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="ChenXi">
  <meta name="keywords" content="">
  
    <meta name="description" content="一、海量数据处理所谓海量数据处理，就是基于海量数据上的存储、处理、操作。 海量：数据量太大，所以导致要么无法在较短时间内迅速解决，要么是数据太大，导致无法一次性装入内存。 在解决办法上，针对时间，可以采用巧妙的算法搭配合适的数据结构，如Bloom Filter&#x2F;Hash&#x2F;bit-map&#x2F;堆&#x2F;数据库或倒排索引&#x2F;Trie树；针对空间，只有一个办法：大而">
<meta property="og:type" content="article">
<meta property="og:title" content="海量数据处理">
<meta property="og:url" content="http://example.com/2019/06/08/D-DataStructureAndAlgorithm/G-BigDataProcess/bigDataProcess/index.html">
<meta property="og:site_name" content="陈曦の博客">
<meta property="og:description" content="一、海量数据处理所谓海量数据处理，就是基于海量数据上的存储、处理、操作。 海量：数据量太大，所以导致要么无法在较短时间内迅速解决，要么是数据太大，导致无法一次性装入内存。 在解决办法上，针对时间，可以采用巧妙的算法搭配合适的数据结构，如Bloom Filter&#x2F;Hash&#x2F;bit-map&#x2F;堆&#x2F;数据库或倒排索引&#x2F;Trie树；针对空间，只有一个办法：大而">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2019-06-07T16:00:00.000Z">
<meta property="article:modified_time" content="2023-06-07T00:28:32.743Z">
<meta property="article:author" content="ChenXi">
<meta property="article:tag" content="数据结构">
<meta property="article:tag" content="算法">
<meta property="article:tag" content="海量数据">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>海量数据处理 - 陈曦の博客</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.4","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>陈曦の博客</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="海量数据处理"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2019-06-08 00:00" pubdate>
          2019年6月8日 凌晨
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          10k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          87 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">海量数据处理</h1>
            
            
              <div class="markdown-body">
                
                <h3 id="一、海量数据处理"><a href="#一、海量数据处理" class="headerlink" title="一、海量数据处理"></a>一、海量数据处理</h3><p>所谓海量数据处理，就是基于海量数据上的存储、处理、操作。</p>
<p>海量：数据量太大，所以导致要么无法在<strong>较短时间内迅速解决</strong>，要么是数据太大，导致<strong>无法一次性装入内存</strong>。</p>
<p>在解决办法上，针对<strong>时间</strong>，可以采用巧妙的<strong>算法</strong>搭配合适的<strong>数据结构</strong>，如Bloom Filter&#x2F;Hash&#x2F;bit-map&#x2F;堆&#x2F;数据库或倒排索引&#x2F;Trie树；针对<strong>空间</strong>，只有一个办法：大而化小，分而治之(hash映射)，即规模太大时，就把规模大化为规模小的，各个击破。</p>
<p>单机及集群问题：单机就是处理装载数据的机器有限(只要考虑cpu，内存，硬盘的数据交互)，而集群，机器有多台，适合分布式处理，并行计算(更多考虑节点和节点间的数据交互)。<br>处理海量数据问题，大致方法有：</p>
<ul>
<li>分而治之&#x2F;hash映射 + hash统计 + 堆&#x2F;快速&#x2F;归并排序</li>
<li>双层桶划分</li>
<li>Bloom Filter&#x2F;Bit map</li>
<li>Trie树&#x2F;数据库&#x2F;倒排索引</li>
<li>外排序</li>
<li>分布式处理之Hadoop&#x2F;Mapreduce</li>
</ul>
<h3 id="二、海量数据问题解决方法"><a href="#二、海量数据问题解决方法" class="headerlink" title="二、海量数据问题解决方法"></a>二、<strong>海量数据问题解决方法</strong></h3><h4 id="2-1-分而治之-x2F-Hash映射-Hash-map统计-堆-x2F-快速-x2F-归并排序"><a href="#2-1-分而治之-x2F-Hash映射-Hash-map统计-堆-x2F-快速-x2F-归并排序" class="headerlink" title="2.1 分而治之&#x2F;Hash映射 + Hash_map统计 + 堆&#x2F;快速&#x2F;归并排序"></a>2.1 <strong>分而治之&#x2F;Hash映射 + Hash_map统计 + 堆&#x2F;快速&#x2F;归并排序</strong></h4><p><strong>Q1：海量日志数据，提取出某日访问百度次数最多的那个IP</strong></p>
<p><strong>方法</strong>：针对这个数据的海量，就是分而治之&#x2F;hash映射 + hash统计 + 堆&#x2F;快速&#x2F;归并排序，即<strong>先映射</strong>，<strong>后统计</strong>，最后<strong>排序</strong>：</p>
<ol>
<li><strong>分而治之&#x2F;hash映射</strong>：针对<strong>数据太大</strong>，内存受限，只能是：<strong>把大文件化成(取模映射)小文件</strong>，即16字方针：大而化小，各个击破，缩小规模，逐个解决</li>
<li><strong>hash_map统计</strong>：当大文件转化了小文件，那么我们便可以采用常规的hash_map(ip，value)来进行<strong>频率统计</strong></li>
<li><strong>堆&#x2F;快速排序</strong>：统计完了之后，便进行<strong>排序</strong>(可采取堆排序)，得到次数最多的IP</li>
</ol>
<p><strong>解答</strong>：首先是这一天，并且是访问百度的日志中的IP取出来，逐个写入到一个大文件中。注意到IP是32位的，最多有个$2^{32}$个IP。同样可以采用映射的方法，比如%1000，把整个大文件映射为1000个小文件，再找出每个小文中出现频率最大的IP（可以采用hash_map对那1000个文件中的所有IP进行频率统计，然后依次找出<strong>各个文件</strong>中频率最大的那个IP）及相应的频率。然后再在这1000个最大的IP中，找出那个频率最大的IP，即为所求。</p>
<p>注：</p>
<ul>
<li><strong>Hash取模</strong>是一种等价映射，不会存在同一个元素分散到不同小文件中的情况，即这里采用的是mod1000算法，那么<strong>相同的IP</strong>在hash取模后，<strong>只可能落在同一个文件中</strong>，不可能被分散的。因为如果两个IP相等，那么经过Hash(IP)之后的哈希值是相同的，将此哈希值取模（如模1000），必定仍然相等。</li>
<li>hash映射：就是为了便于计算机在有限的内存中处理大量数据，从而通过一种映射散列的方式让数据均匀分布在对应的内存位置(如大数据通过取余的方式映射成小树存放在内存中，或大文件映射成多个小文件)，而这个映射散列方式便是hash函数，设计的<strong>好的hash函数能让数据均匀分布而减少冲突</strong>。尽管数据映射到了另外一些不同的位置，但数据还是原来的数据，只是代替和表示这些原始数据的形式发生了变化而已。</li>
</ul>
<p><strong>Q2：寻找热门查询，300万个查询字符串中统计最热门的10个查询</strong></p>
<p><strong>题目</strong>：搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。假设目前有一千万个记录（这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门），请统计最热门的10个查询串，要求使用的内存不能超过1G。<br><strong>解答</strong>：由上面第1题可知，数据大则划为小的，如一亿个IP求Top 10，可先%1000将IP分到1000个小文件中去，并保证一种IP只出现在一个文件中，再对每个小文件中的IP进行Hashmap计数统计并按数量排序，最后归并或者最小堆依次处理每个小文件的top10以得到最后的结果。<br>但如果<strong>数据规模比较小</strong>，能<strong>一次性装入内存</strong>呢？比如这第2题，虽然有一千万个Query，但是由于重复度比较高，因此事实上只有300万的Query，每个Query 255Byte，因此可以考虑把他们都放进内存中去（300万个字符串假设没有重复，都是最大长度，那么最多占用内存3M*1K&#x2F;4&#x3D;0.75G。所以，可以将所有字符串都存放在内存中进行处理），而需要一个合适的数据结构，在这里，HashTable是绝对优先的选择。<br>所以放弃分而治之&#x2F;hash映射的步骤，直接上<strong>hash统计</strong>，然后<strong>排序</strong>。因此，针对此类典型的TOP K问题，采取的对策往往是：Hashmap + 堆。</p>
<p>如下所示：</p>
<ol>
<li><strong>Hashmap统计</strong>：先对这批<strong>海量数据预处理</strong>。具体方法是：维护一个Key为Query字串，Value为该Query出现次数的HashTable，即hash_map(Query，Value)，每次读取一个Query，如果该字串不在Table中，那么加入该字串，并且将Value值设为1；如果该字串在Table中，那么将该字串的计数加一即可。最终在<strong>O(N)的时间复杂度</strong>内用Hash表完成了统计；</li>
<li><strong>堆排序</strong>：借助堆这个数据结构，找出Top K，时间复杂度为N’logK。即借助堆结构，可以在log量级的时间内查找和调整&#x2F;移动。因此，维护一个K(该题目中是10)大小的最小堆，然后遍历300万的Query，分别和根元素进行对比。所以，最终的时间复杂度是：O(N)+N’*O(logK),(N为1000万，N’为300万)。</li>
<li><strong>堆排序思路</strong>：维护k个元素的最小堆，即用容量为k的最小堆存储最先遍历到的k个数，并假设它们即是最大的k个数，建堆时间复杂度O(k)，并调整堆(时间复杂度(logk)后，有$k1&gt;k2&gt;…k_{min}($$k_{min}$设为小顶堆中最小元素)。继续遍历数列，每次遍历一个元素x，与堆顶元素比较，若$x&gt;k_{min}$，则更新堆（x入堆，用时logk），否则不更新堆。这样下来，总费时O(k * logk+（n-k）* logk)&#x3D;O(n*logk)。此方法得益于在堆中，查找等各项操作时间复杂度均为logk。</li>
</ol>
<p>当然，也可以采用Trie树，关键字域存该查询串出现的次数，没有出现为0。最后用10个元素的最小堆来对出现频率进行排序。</p>
<p><strong>Q3：有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词</strong></p>
<p>此时，文件很大，而且内存受限，<strong>方法</strong>：</p>
<ol>
<li><strong>分而治之&#x2F;hash映射</strong>：顺序读文件中，对于每个词x，取hash(x)%5000，然后按照该值存到5000个小文件中。这样每个文件大概是200k左右。如果其中的有的文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的<strong>小文件的大小都不超过1M</strong></li>
<li><strong>hash_map统计</strong>：对每个小文件，采用Trie树&#x2F;Hash_map等<strong>统计</strong>每个文件中出现的词以及相应的频率</li>
<li><strong>堆&#x2F;归并排序</strong>：每个小文件取出出现频率最大的100个词（可以用含100个结点的最小堆）后，再把100个词及相应的频率存入文件，这样又得到了5000个文件，最后就是把这5000个文件进行<strong>归并</strong>（类似于归并排序）的过程</li>
</ol>
<p><strong>Q4：海量数据分布在100台电脑中，高效统计出这批数据的TOP10</strong></p>
<p>如果每个数据元素只出现在某一台机器中，那么可以采取以下步骤统计出现次数TOP10的数据元素：</p>
<ol>
<li><strong>堆排序：</strong>在每台电脑上求出TOP10，可以采用包含10个元素的堆完成（TOP10小，用最大堆，TOP10大，用最小堆）。</li>
<li>求出每台电脑上的TOP10后，然后把这100台电脑上的TOP10组合起来，共1000个数据，再利用上面类似的方法求出TOP10就可以了。</li>
</ol>
<p>如果同一个元素重复出现，且在不同的电脑中，如下例子所述：2台机器求top2的情况来说：第一台：a(50)，b(50)，c(49)，d(49)，e(0)，f(0)；第二台：a(0)，b(0)，c(49)，d(49)，e(50),f(50)。</p>
<p>这个时候，有两种方法：</p>
<ul>
<li>遍历一遍所有数据，重新hash取模，如此使得同一个元素<strong>只出现在单独的一台电脑中</strong>，然后采用上面所说的方法，统计每台电脑中各个元素的出现次数找出TOP10，继而组合100台电脑上的TOP10，找出最终的TOP10。</li>
<li>暴力求解：直接统计统计每台电脑中各个元素的出现次数，然后把同一个元素在不同机器中的出现次数相加，最终从所有数据中找出TOP10。</li>
</ul>
<p><strong>Q5：有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复，要求按照query的频度排序</strong></p>
<p><strong>方案1：直接处理：</strong></p>
<ol>
<li>hash映射：顺序读取10个文件，按照hash(query)%10的结果将query写入到另外10个文件中。这样新生成的文件每个的大小大约也1G（假设hash函数是随机的）。</li>
<li>hash_map统计：找一台内存在2G左右的机器，依次对用hash_map(query, query_count)来统计每个query出现的次数。注：hash_map(query,query_count)是用来统计每个query的出现次数，不是存储他们的值，出现一次，则count+1。</li>
<li>堆&#x2F;快速&#x2F;归并排序：利用快速&#x2F;堆&#x2F;归并排序按照出现次数进行排序，将排序好的query和对应的query_cout输出到文件中，这样得到了10个排好序的文件（记为）。最后，对这10个文件进行归并排序（内排序与外排序相结合）。</li>
</ol>
<p><strong>方案2</strong>：一般query的总量是有限的，只是重复的次数比较多而已，可能对于所有的query，一次性就可以加入到内存了。这样，我们就可以采用Trie树&#x2F;Hash_map等直接来统计每个query出现的次数，然后按出现次数做快速&#x2F;堆&#x2F;归并排序就可以了。<br><strong>方案3</strong>：与方案1类似，但在做完hash，分成多个文件后，可以交给多个文件来处理，采用分布式的架构来处理（比如MapReduce），最后再进行合并。</p>
<p><strong>Q6：给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，找出a、b文件共同的url</strong></p>
<p>可以估计每个文件的大小为5G×64&#x3D;320G，远远大于内存限制的4G，所以不可能将其完全加载到内存中处理，考虑采取分而治之的方法：</p>
<ol>
<li>分而治之&#x2F;hash映射：遍历文件a，对每个url求取，然后根据所取得的值将url分别存储到1000个小文件中。这样每个小文件的大约为300M。遍历文件b，采取和a<strong>相同的方式</strong>将url分别存储到1000小文件中。这样处理后，所有可能相同的url都在对应的小文件中，不对应的小文件不可能有相同的url。然后只要求出<strong>1000对</strong>小文件中相同的url即可。</li>
<li>hash_set统计：求每对小文件中相同的url时，可以把其中一个小文件的url存储到hash_set中。然后遍历另一个小文件的每个url，看其是否在刚才构建的hash_set中，如果是，那么就是共同的url，存到文件里面就可以了。</li>
</ol>
<p><strong>Q7：怎么在海量数据中找出重复次数最多的一个？</strong></p>
<p>方案：先做hash，然后求模映射为小文件，求出每个小文件中重复次数最多的一个，并记录重复次数。然后找出上一步求出的数据中重复次数最多的一个就是所求。</p>
<p><strong>Q8：上千万或上亿数据（有重复），统计其中出现次数最多的前N个数据</strong></p>
<p>方案：上千万或上亿的数据，内存应该能存下，所以考虑采用hash_map&#x2F;搜索二叉树&#x2F;红黑树等来进行统计次数，然后利用堆取出前N个出现次数最多的数据。</p>
<p><strong>Q9：一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析。</strong></p>
<p><strong>方案1</strong>：如果文件比较大，无法一次性读入内存，可以采用hash取模的方法，将大文件分解为多个小文件，对于单个小文件利用hash_map统计出每个小文件中10个最常出现的词，然后再进行归并处理，找出最终的10个最常出现的词。<br><strong>方案2</strong>：通过hash取模将大文件分解为多个小文件后，除了可以用hash_map统计出每个小文件中10个最常出现的词，也可以用Trie树统计每个词出现的次数，时间复杂度是O(n*le)（le表示单词的平准长度），最终同样找出出现最频繁的前10个词（可用堆来实现），时间复杂度是O(n*lg10)。</p>
<p><strong>Q10：1000万字符串，其中有些是重复的，需要把重复的全部去掉，保留没有重复的字符串。请怎么设计和实现？</strong></p>
<p><strong>方案1</strong>：这题用Trie树比较合适，hash_map也行。<br><strong>方案2</strong>：1000w的数据规模插入操作完全不现实，基于hash的实现不会比红黑树好太多，使用vector+sort+unique都要可行许多，还是先hash成小文件分开处理再综合。</p>
<p><strong>Q11：一个文本文件，找出前10个经常出现的词，但这次文件比较长，说是上亿行或十亿行，总之无法一次读入内存，问最优解</strong></p>
<p>首先根据用hash并求模，将文件分解为多个小文件，对于单个文件利用上题的方法求出每个文件件中10个最常出现的词。然后再进行归并处理，找出最终的10个最常出现的词</p>
<p><strong>Q12：100w个数中找出最大的100个数</strong></p>
<p><strong>方案1</strong>：采用局部淘汰法。选取前100个元素，并<strong>排序</strong>，记为序列L。然后一次扫描剩余的元素x，与排好序的100个元素中<strong>最小的元素比</strong>，如果比这个最小的要大，那么把这个最小的元素<strong>删除</strong>，并把x利用<strong>插入排序</strong>的思想，插入到序列L中。依次循环，知道扫描了所有的元素。复杂度为O(100w * 100)。<br><strong>方案2</strong>：采用快速排序的思想，每次分割之后只考虑比轴大的一部分，知道比轴大的一部分在比100多的时候，采用传统排序算法排序，取前100个。复杂度为O(100w * 100)。<br><strong>方案3</strong>：用一个含100个元素的最小堆完成。复杂度为O(100w * lg100)</p>
<h4 id="2-2-多层划分"><a href="#2-2-多层划分" class="headerlink" title="2.2 多层划分"></a>2.2 多层划分</h4><p><strong>多层划分</strong>：本质上还是分而治之的思想，重在“分”的技巧上！<br><strong>适用范围</strong>：第k大，中位数，不重复或重复的数字<br><strong>基本原理及要点</strong>：因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。</p>
<p><strong>Q1：2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数</strong><br>类似鸽巢原理，整数个数为$2^{32}$，即可以将这$2^{32}$个数，划分为$2^8$个区域(比如用单个文件代表一个区域)，然后将数据分离到不同的区域，然后不同的区域在利用bitmap就可以直接解决了。也就是说只要有足够的磁盘空间，就可以很方便的解决。<br><strong>Q2：5亿个int找中位数</strong><br><strong>思路一</strong>：首先将int划分为$2^{16}$个区域，然后读取数据统计落到各个区域里的数的个数，之后我们根据统计结果就可以判断中位数落到那个区域，同时知道这个区域中的第几大数刚好是中位数。然后第二次扫描只统计落在这个区域中的那些数就可以。<br>实际上，如果不是int是int64，我们可以经过3次这样的划分即可降低到可以接受的程度。即可以先将int64分成$2^{24}$个区域，然后确定区域的第几大数，在将该区域分成$2^{20}$个子区域，然后确定是子区域的第几大数，然后子区域里的数的个数只有$2^{20}​$，就可以直接利用direct addr table进行统计了。<br><strong>思路二：</strong>同样需要做两遍统计，如果数据存在硬盘上，就需要读取2次。<br>方法同基数排序有些像，开一个大小为65536的Int数组，第一遍读取，统计Int32的高16位的情况，也就是0-65535，都算作0,65536 - 131071都算作1。就相当于用该数除以65536。Int32 除以 65536的结果不会超过65536种情况，因此开一个长度为65536的数组计数就可以。每读取一个数，数组中对应的计数+1，考虑有负数的情况，需要将结果加32768后，记录在相应的数组内。<br>第一遍统计之后，遍历数组，逐个累加统计，看中位数处于哪个区间，比如处于区间k，那么0- k-1的区间里数字的数量sum应该&lt;n&#x2F;2（2.5亿）。而k+1 - 65535的计数和也&lt;n&#x2F;2，第二遍统计同上面的方法类似，但这次只统计处于区间k的情况，也就是说(x &#x2F; 65536) + 32768 &#x3D; k。统计只统计低16位的情况。并且利用刚才统计的sum，比如sum &#x3D; 2.49亿，那么现在就是要在低16位里面找100万个数(2.5亿-2.49亿)。这次计数之后，再统计一下，看中位数所处的区间，最后将高位和低位组合一下就是结果了。</p>
<h4 id="2-3-Bloom-filter-x2F-Bitmap"><a href="#2-3-Bloom-filter-x2F-Bitmap" class="headerlink" title="2.3 Bloom filter&#x2F;Bitmap"></a>2.3 <strong>Bloom filter&#x2F;Bitmap</strong></h4><p><strong>适用范围</strong>：可以用来实现<strong>数据字典</strong>，进行数据的<strong>判重</strong>，或者集合求<strong>交集</strong></p>
<p><strong>基本原理及要点</strong>：对于原理来说很简单，位数组+k个独立hash函数。将hash函数对应的值的位数组置1，查找时如果发现所有hash函数对应位都是1说明存在，很明显这个过程并不保证查找的结果是100%正确的。同时也不支持删除一个已经插入的关键字，因为该关键字对应的位会牵动到其他的关键字。所以一个简单的改进就是 counting Bloom filter，用一个counter数组代替位数组，就可以支持删除了。<br>还有一个比较重要的问题，如何根据输入元素个数n，确定位数组m的大小及hash函数个数。当hash函数个数k&#x3D;(ln2)*(m&#x2F;n)时错误率最小。在错误率不大于E的情况下，m至少要等于n*lg(1&#x2F;E)才能表示任意n个元素的集合。但m还应该更大些，因为还要保证bit数组里至少一半为0，则m应该&gt;&#x3D;nlg(1&#x2F;E)*lge 大概就是nlg(1&#x2F;E)1.44倍(lg表示以2为底的对数)。<br>举个例子假设错误率为0.01，则此时m应大概是n的13倍。这样k大概是8个。<br>注意这里m与n的单位不同，m是bit为单位，而n则是以元素个数为单位(准确的说是不同元素的个数)。通常单个元素的长度都是有很多bit的。所以使用bloom filter内存上通常都是节省的。<br><strong>扩展：</strong><br>Bloom filter将集合中的元素映射到位数组中，用k（k为哈希函数个数）个映射位是否全1表示元素在不在这个集合中。Counting bloom filter（CBF）将位数组中的每一位扩展为一个counter，从而支持了元素的删除操作。Spectral Bloom Filter（SBF）将其与集合元素的出现次数关联。SBF采用counter中的最小值来近似表示元素的出现频率。<br><strong>Q1：A,B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，找出A,B文件共同的URL，如果是三个乃至n个文件呢？</strong><br>根据这个问题首先计算下内存的占用，4G&#x3D;2^32大概是40亿*8大概是340亿，n&#x3D;50亿，如果按出错率0.01算需要的大概是650亿个bit。现在可用的是340亿，相差并不多，这样可能会使出错率上升些。另外如果这些urlip是一一对应的，就可以转换成ip，则大大简单了。<br>同时，上文题：给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，找出a、b文件共同的url？如果允许有一定的错误率，可以使用Bloom filter，4G内存大概可以表示340亿bit。将其中一个文件中的url使用Bloom filter映射为这340亿bit，然后挨个读取另外一个文件的url，检查是否与Bloom filter，如果是，那么该url应该是共同的url（注意会有一定的错误率）。</p>
<p><strong>Q2：在2.5亿个整数中找出不重复的整数，内存不足以容纳这2.5亿个整数</strong><br><strong>方案1</strong>：采用2-Bitmap（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，共需内存2^32 * 2 bit&#x3D;1 GB内存，还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可。<br><strong>方案2</strong>：也可采用与第1题类似的方法，进行划分小文件的方法。然后在小文件中找出不重复的整数，并排序。然后再进行归并，注意去除重复的元素。<br><strong>Q3：给40亿个不重复的unsigned int的整数，没排过序，然后再给一个数，如何快速判断这个数是否在那40亿个数当中</strong><br>frome oo，用位图&#x2F;Bitmap的方法，申请512M的内存，一个bit位代表一个unsigned int值。读入40亿个数，设置相应的bit位，读入要查询的数，查看相应bit位是否为1，为1表示存在，为0表示不存在。</p>
<h4 id="2-4-Trie树-x2F-数据库-x2F-倒排索引"><a href="#2-4-Trie树-x2F-数据库-x2F-倒排索引" class="headerlink" title="2.4 Trie树&#x2F;数据库&#x2F;倒排索引"></a>2.4 <strong>Trie树&#x2F;数据库&#x2F;倒排索引</strong></h4><p><strong>Trie树</strong></p>
<p><strong>适用范围</strong>：数据量大，重复多，但是数据种类小可以放入内存<br><strong>基本原理及要点</strong>：实现方式，节点孩子的表示方式<br>扩展：压缩实现。<br><strong>问题实例：</strong><br>Q1：上面的题：寻找热门查询：查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个，每个不超过255字节。<br>Q2：上面的题：有10个文件，每个文件1G，每个文件的每一行都存放的是用户的query，每个文件的query都可能重复。要你按照query的频度排序。<br>Q3：1000万字符串，其中有些是相同的(重复)，需要把重复的全部去掉，保留没有重复的字符串。请问怎么设计和实现？<br>Q4：上面的题：一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词。</p>
<p>其解决方法是：用Trie树统计每个词出现的次数，时间复杂度是O(n*le)（le表示单词的平准长度），然后是找出出现最频繁的前10个词。</p>
<p><strong>数据库索引</strong><br><strong>适用范围</strong>：大数据量的增删改查<br><strong>基本原理及要点</strong>：利用数据的设计实现方法，对海量数据的增删改查进行处理。</p>
<p><strong>倒排索引(Inverted index)</strong></p>
<p><strong>适用范围</strong>：搜索引擎，关键字查询<br><strong>基本原理及要点</strong>：一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。<br>以英文为例，下面是要被索引的文本：<br>T0 &#x3D; “it is what it is”<br>T1 &#x3D; “what is it”<br>T2 &#x3D; “it is a banana”<br>我们就能得到下面的反向文件索引：<br>“a”: {2}<br>“banana”: {2}<br>“is”: {0, 1, 2}<br>“it”: {0, 1, 2}<br>“what”: {0, 1}<br>检索的条件”what”,”is”和”it”将对应集合的交集。<br>正向索引开发出来用来存储每个文档的单词的列表。正向索引的查询往往满足每个文档有序频繁的全文查询和每个单词在校验文档中的验证这样的查询。在正向索引中，文档占据了中心的位置，每个文档指向了一个它所包含的索引项的序列。也就是说文档指向了它包含的那些单词，而反向索引则是单词指向了包含它的文档，很容易看到这个反向的关系。<br>扩展：</p>
<p>问题实例：文档检索系统，查询那些文件包含了某单词，比如常见的学术论文的关键字搜索。</p>
<h4 id="2-5-外排序"><a href="#2-5-外排序" class="headerlink" title="2.5 外排序"></a>2.5 外排序</h4><p><strong>适用范围</strong>：大数据的排序，去重<br><strong>基本原理及要点</strong>：外排序的归并方法，置换选择败者树原理，最优归并树<br>问题实例：<br>Q1：有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16个字节，内存限制大小是1M。返回频数最高的100个词。<br>这个数据具有很明显的特点，词的大小为16个字节，但是内存只有1M做hash明显不够，所以可以用来排序。内存可以当输入缓冲区使用。</p>
<h4 id="2-6-分布式处理之Mapreduce"><a href="#2-6-分布式处理之Mapreduce" class="headerlink" title="2.6 分布式处理之Mapreduce"></a>2.6 <strong>分布式处理之Mapreduce</strong></h4><p>MapReduce是一种计算模型，简单的说就是将大批量的工作（数据）分解（MAP）执行，然后再将结果合并成最终结果（REDUCE）。这样做的好处是可以在任务被分解后，可以通过大量机器进行并行计算，减少整个操作的时间。但如果你要我再通俗点介绍，那么，说白了，Mapreduce的原理就是一个归并排序。<br>适用范围：数据量大，但是数据种类小可以放入内存<br>基本原理及要点：将数据交给不同的机器去处理，数据划分，结果归约。<br>问题实例：<br>Q1：The canonical example application of MapReduce is a process to count the appearances of each different word in a set of documents:<br>Q2：海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10。<br>Q3：一共有N个机器，每个机器上有N个数。每个机器最多存O(N)个数并对它们操作。如何找到N^2个数的中数(median)？</p>
<h4 id="2-7-其他"><a href="#2-7-其他" class="headerlink" title="2.7 其他"></a>2.7 其他</h4><p>题目：<strong>非常大的文件，装不进内存。每行一个int类型数据，现在要随机取100个数</strong></p>
<p>针对此题，我们可以借鉴操作系统内存分页系统设计(映射+建索引)，做出如下解决方案：<br>物理内存分页，一个物理页的大小为4K字节，第0个物理页从物理地址 0x00000000 处开始。由于页的大小为4KB，就是0x1000字节，所以第1页从物理地址 0x00001000 处开始。第2页从物理地址 0x00002000 处开始。可以看到由于页的大小是4KB，所以只需要32bit的地址中高20bit来寻址物理页。<br>操作系统中的方法，先生成4G的地址表，在把这个表划分为小的4M的小文件做个索引，二级索引。30位前十位表示第几个4M文件，后20位表示在这个4M文件的第几个，等等，基于key value来设计存储，用key来建索引。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/" class="category-chain-item">数据结构与算法</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">#数据结构</a>
      
        <a href="/tags/%E7%AE%97%E6%B3%95/">#算法</a>
      
        <a href="/tags/%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE/">#海量数据</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>海量数据处理</div>
      <div>http://example.com/2019/06/08/D-DataStructureAndAlgorithm/G-BigDataProcess/bigDataProcess/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>ChenXi</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2019年6月8日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2019/06/08/D-DataStructureAndAlgorithm/G-BigDataProcess/bigData/" title="海量数据处理">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">海量数据处理</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2019/02/14/D-DataStructureAndAlgorithm/A-DataStructure/base-data-structure/" title="数据结构">
                        <span class="hidden-mobile">数据结构</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
